{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ModernOctave/Thermal-Image-Human-Detection/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvHS-zQk8-wp"
   },
   "source": [
    "# Install Dependancies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the required dependencies for making a custom model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d-EigR5zlUz"
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow 2.0\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes in Google Collab\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "# Else if on local system without GPU ignore this error or comment out the below line\n",
    "assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataset from the included images in the [dataset](dataset) folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    human_paths = glob.glob('./dataset/human/*.jpg')\n",
    "    no_human_paths = glob.glob('./dataset/no_human/*.jpg')\n",
    "    if len(human_paths) == 0 or len(no_human_paths) == 0:\n",
    "        raise Exception('Dataset could not be found!')\n",
    "    human_images = [np.split(cv.imread(path), 3, axis=2)[0] for path in human_paths]\n",
    "    no_human_images = [np.split(cv.imread(path), 3, axis=2)[0] for path in no_human_paths]\n",
    "    random.shuffle(human_images)\n",
    "    random.shuffle(no_human_images)\n",
    "    half_size = min(len(human_images), len(no_human_images))\n",
    "    dataset = list(zip(human_images[:half_size], np.ones(half_size))) + list(zip(no_human_images[:half_size], np.zeros(half_size)))\n",
    "    random.shuffle(dataset)\n",
    "    split_size = int(len(dataset) * 0.8)\n",
    "    train_dataset = dataset[:split_size]\n",
    "    test_dataset = dataset[split_size:]\n",
    "    train_images, train_labels = zip(*train_dataset)\n",
    "    test_images, test_labels = zip(*test_dataset)\n",
    "    train_images, test_images = np.array(train_images), np.array(test_images)\n",
    "    train_labels, test_labels = np.array(train_labels), np.array(test_labels)\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = createDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQDTxvHBd0Wg"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE8cSAGShXvZ"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model architecture using keras's sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_k6qaJlpeQu7"
   },
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "                                     \n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation=tf.nn.relu, input_shape=(24, 32, 1)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n",
    "        \n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n",
    "        \n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(units=128, activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.Dense(units=128, activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.Dense(units=64, activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.Dense(units=1, activation=tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    return cnn_model\n",
    "  \n",
    "cnn_model = build_cnn_model()\n",
    "\n",
    "# Initialize the model by passing some data through\n",
    "# cnn_model.predict(train_images[[0]])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the summary of the layers in the model.\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjZ3zX0hX-Q5"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load a saved / pre-trained model by specifying the path to the model in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwV0_q9PgyBI"
   },
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.load_model(\"models/MLX90640-Human-Detection\")\n",
    "\n",
    "# Print the summary of the layers in the model.\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model for a fixed number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTNuDdBMX7xc"
   },
   "outputs": [],
   "source": [
    "cnn_model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or train the model until the testing accuracy stops improving. This way can help prevent overfitting of the model to the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.5\n",
    "val_acc = 0.5\n",
    "last_acc = 0\n",
    "last_val_acc = 0\n",
    "while val_acc >= last_val_acc and acc > last_acc:\n",
    "  h = cnn_model.fit(train_images, train_labels, epochs=1, validation_data=(test_images, test_labels)).history\n",
    "  last_acc = acc\n",
    "  last_val_acc = val_acc\n",
    "  acc = h['accuracy'][-1]\n",
    "  val_acc = h['val_accuracy'][-1]\n",
    "  \n",
    "print(round(val_acc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model for future use by specifying the path to the location to save it at in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(cnn_model, \"models/MLX90640-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS5yngy6_1dO"
   },
   "source": [
    "## Test the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test the accuracy of the model on the test set by running the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExSEsv0b_6Nx"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = cnn_model.evaluate(test_images, test_labels, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPehCNxKIZwhZ61eTGu6GaJ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Thermal_Image_Human_Detection.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
