{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thermal_Image_Human_Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUqFMgfoa3EErmWwQfB6+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ModernOctave/Thermal-Image-Human-Detection/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "HG40xyEpbWwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create file containing all urls of dataset parts."
      ],
      "metadata": {
        "id": "iYkLvXhObsM9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux_mq_y5ZL8-",
        "outputId": "871d0688-c5d0-4594-8b5b-14fb62774d4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset_parts.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile dataset_parts.txt\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.00\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.01\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.02\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.03\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.04\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.05\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.06\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.07\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.08\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.09\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.10\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/FLIR_ADAS_v2.zip.11\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/parts/md5sums_parts.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataset_parts.txt\n",
        "https://adas-dataset-v2.flirconservator.com/dataset/full/FLIR_ADAS_v2.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNN7UQz0zYfM",
        "outputId": "38e942f9-2eb0-4e24-94ec-63a0780df2d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dataset_parts.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download all parts"
      ],
      "metadata": {
        "id": "ufFfDNnWbhb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat dataset_parts.txt | xargs -n 1 -P 0 wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moQmrno1aU7P",
        "outputId": "1c7c24aa-cdc6-479d-e52e-c7abab76e55d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-10 09:00:35--  https://adas-dataset-v2.flirconservator.com/dataset/full/FLIR_ADAS_v2.zip\n",
            "Resolving adas-dataset-v2.flirconservator.com (adas-dataset-v2.flirconservator.com)... 108.156.120.82, 108.156.120.128, 108.156.120.101, ...\n",
            "Connecting to adas-dataset-v2.flirconservator.com (adas-dataset-v2.flirconservator.com)|108.156.120.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11865443849 (11G) [application/zip]\n",
            "Saving to: ‘FLIR_ADAS_v2.zip’\n",
            "\n",
            "FLIR_ADAS_v2.zip    100%[===================>]  11.05G   206MB/s    in 64s     \n",
            "\n",
            "2022-04-10 09:01:39 (177 MB/s) - ‘FLIR_ADAS_v2.zip’ saved [11865443849/11865443849]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verify parts checksums"
      ],
      "metadata": {
        "id": "Yp0UfqUsbvlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!md5sum -c md5sums_parts.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiBmWm8Db9GP",
        "outputId": "d6403ddb-1942-4622-a11f-50ef5dae0b26"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLIR_ADAS_v2.zip.00: OK\n",
            "FLIR_ADAS_v2.zip.01: OK\n",
            "FLIR_ADAS_v2.zip.02: OK\n",
            "FLIR_ADAS_v2.zip.03: OK\n",
            "FLIR_ADAS_v2.zip.04: OK\n",
            "FLIR_ADAS_v2.zip.05: OK\n",
            "FLIR_ADAS_v2.zip.06: OK\n",
            "FLIR_ADAS_v2.zip.07: OK\n",
            "FLIR_ADAS_v2.zip.08: OK\n",
            "FLIR_ADAS_v2.zip.09: OK\n",
            "FLIR_ADAS_v2.zip.10: OK\n",
            "FLIR_ADAS_v2.zip.11: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine and extract"
      ],
      "metadata": {
        "id": "ADXAEfTzcMht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat FLIR_ADAS_v2.zip.* > FLIR_ADAS_v2.zip"
      ],
      "metadata": {
        "id": "wW7bmwtYr6eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q FLIR_ADAS_v2.zip"
      ],
      "metadata": {
        "id": "VZY5Ic5CcO38"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove temp files"
      ],
      "metadata": {
        "id": "r8VNMDcYdQTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm FLIR* dataset_parts.txt md5sums_parts.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sksyn1JdTKl",
        "outputId": "daba27a6-79c1-44ea-d83d-ff80feeffbe9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'md5sums_parts.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create datasets"
      ],
      "metadata": {
        "id": "r7x-jwDpzegI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import requests\n",
        "from pycocotools.coco import COCO\n",
        "import random"
      ],
      "metadata": {
        "id": "5d-EigR5zlUz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"images_thermal_train/\"\n",
        "coco_annotation_file_path = dataset_path+\"coco.json\"\n",
        "coco_annotation = COCO(annotation_file=coco_annotation_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxSh-XYT3OeU",
        "outputId": "503c312f-049e-48a2-fdff-db230a711f96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.88s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all images\n",
        "img_ids = coco_annotation.getImgIds()[:1000]\n",
        "# print(len(img_ids))\n",
        "\n",
        "# Get category info\n",
        "cat_ids = coco_annotation.getCatIds()\n",
        "cat = dict(zip(cat_ids,[cat['name'] for cat in coco_annotation.loadCats(cat_ids)]))\n",
        "# print(cat)\n",
        "\n",
        "human = []\n",
        "no_human = []\n",
        "\n",
        "for i, img_id in enumerate(img_ids):\n",
        "  # Open img\n",
        "  img_info = coco_annotation.loadImgs([img_id])[0]\n",
        "  img_file_name = img_info[\"file_name\"]\n",
        "  im = np.array(Image.open(dataset_path+img_file_name))\n",
        "\n",
        "  # Get all the annotations for the specified image.\n",
        "  ann_ids = coco_annotation.getAnnIds(imgIds=[img_id], iscrowd=None)\n",
        "  anns = coco_annotation.loadAnns(ann_ids)\n",
        "\n",
        "  if 'person' in [cat[ann['category_id']] for ann in anns]:\n",
        "    human.append(im)\n",
        "  else:\n",
        "    no_human.append(im)\n",
        "  \n",
        "  if i%(int(len(img_ids)/10)) == 0:\n",
        "    print(str(int(i/len(img_ids)*100))+\"%\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training dataset created!\")\n",
        "# print('person' in [cat[ann['category_id']] for ann in anns])\n",
        "# im = Image.open('images_thermal_train/'+img_file_name)\n",
        "# display(im)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcbo5R4U3PPu",
        "outputId": "bf037b69-7399-4b75-e544-0d8b52302ac2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0%\n",
            "10%\n",
            "20%\n",
            "30%\n",
            "40%\n",
            "50%\n",
            "60%\n",
            "70%\n",
            "80%\n",
            "90%\n",
            "Training dataset created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "half_size = min(len(human),len(no_human))\n",
        "print(half_size)\n",
        "train_images = human[:half_size]+no_human[:half_size]\n",
        "train_labels = list(np.ones(half_size))+list(np.zeros(half_size))\n",
        "print(len(train_labels))\n",
        "dataset = list(zip(train_images, train_labels))\n",
        "random.shuffle(dataset)\n",
        "train_images, train_labels = zip(*dataset)\n",
        "train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)\n",
        "train_labels = np.array(train_labels).astype(np.int64)\n",
        "human = None\n",
        "no_human = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh-byVsFzy-1",
        "outputId": "170caeff-5ece-44ea-a364-98dbf45b3851"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "168\n",
            "336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(train_labels)/len(train_labels)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXJIPnGJA5Ok",
        "outputId": "903f2a0c-54cb-484a-91b9-262b14381e70"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_ids = coco_annotation.getCatIds()\n",
        "print(f\"Number of Unique Categories: {len(cat_ids)}\")\n",
        "print(\"Category IDs:\")\n",
        "print(cat_ids)  # The IDs are not necessarily consecutive.\n",
        "\n",
        "# Category IDs.\n",
        "cat_ids = coco_annotation.getCatIds()\n",
        "print(f\"Number of Unique Categories: {len(cat_ids)}\")\n",
        "print(\"Category IDs:\")\n",
        "print(cat_ids)  # The IDs are not necessarily consecutive.\n",
        "\n",
        "# All categories.\n",
        "cats = coco_annotation.loadCats(cat_ids)\n",
        "cat_names = [cat[\"name\"] for cat in cats]\n",
        "print(\"Categories Names:\")\n",
        "print(cat_names)\n",
        "\n",
        "# Category ID -> Category Name.\n",
        "query_id = cat_ids[0]\n",
        "query_annotation = coco_annotation.loadCats([query_id])[0]\n",
        "query_name = query_annotation[\"name\"]\n",
        "query_supercategory = query_annotation[\"supercategory\"]\n",
        "print(\"Category ID -> Category Name:\")\n",
        "print(\n",
        "    f\"Category ID: {query_id}, Category Name: {query_name}, Supercategory: {query_supercategory}\"\n",
        ")\n",
        "\n",
        "# Category Name -> Category ID.\n",
        "query_name = cat_names[0]\n",
        "query_id = coco_annotation.getCatIds(catNms=[query_name])[0]\n",
        "print(\"Category Name -> ID:\")\n",
        "print(f\"Category Name: {query_name}, Category ID: {query_id}\")\n",
        "\n",
        "# Get the ID of all the images containing the object of the category.\n",
        "img_ids = coco_annotation.getImgIds(catIds=[query_id])\n",
        "print(f\"Number of Images Containing {query_name}: {len(img_ids)}\")\n",
        "\n",
        "# Pick one image.\n",
        "img_id = img_ids[2]\n",
        "img_info = coco_annotation.loadImgs([img_id])[0]\n",
        "img_file_name = img_info[\"file_name\"]\n",
        "print(img_info)\n",
        "print(\n",
        "    f\"Image ID: {img_id}, File Name: {img_file_name}\"\n",
        ")\n",
        "\n",
        "# Get all the annotations for the specified image.\n",
        "ann_ids = coco_annotation.getAnnIds(imgIds=[img_id], iscrowd=None)\n",
        "anns = coco_annotation.loadAnns(ann_ids)\n",
        "print(f\"Annotations for Image ID {img_id}:\")\n",
        "print(anns)\n",
        "\n",
        "# Use URL to load image.\n",
        "im = Image.open(\"images_thermal_train/\"+img_file_name)\n",
        "\n",
        "# Save image and its labeled version.\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(np.asarray(im))\n",
        "plt.savefig(f\"{img_id}.jpg\", bbox_inches=\"tight\", pad_inches=0)\n",
        "# Plot segmentation and bounding box.\n",
        "coco_annotation.showAnns(anns, draw_bbox=True)\n",
        "plt.savefig(f\"{img_id}_annotated.jpg\", bbox_inches=\"tight\", pad_inches=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1bpSuetz0n-",
        "outputId": "f3765a94-c1d2-4a3b-ccdd-f6f704f51671"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=3.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Number of Unique Categories: 80\n",
            "Category IDs:\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
            "Number of Unique Categories: 80\n",
            "Category IDs:\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]\n",
            "Categories Names:\n",
            "['person', 'bike', 'car', 'motor', 'airplane', 'bus', 'train', 'truck', 'boat', 'light', 'hydrant', 'sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'deer', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'stroller', 'rider', 'scooter', 'vase', 'scissors', 'face', 'other vehicle', 'license plate']\n",
            "Category ID -> Category Name:\n",
            "Category ID: 1, Category Name: person, Supercategory: unknown\n",
            "Category Name -> ID:\n",
            "Category Name: person, Category ID: 1\n",
            "Number of Images Containing person: 8205\n",
            "{'extra_info': {'hours': 'day', 'scene': 'highway', 'video_id': 'GzdKTLbkG5F7gAunM', 'weather': 'partly_cloudy'}, 'file_name': 'data/video-GzdKTLbkG5F7gAunM-frame-000138-hGJXmoECsAKraavzR.jpg', 'height': 512, 'id': 2, 'subdirs': 'data', 'width': 640}\n",
            "Image ID: 2, File Name: data/video-GzdKTLbkG5F7gAunM-frame-000138-hGJXmoECsAKraavzR.jpg\n",
            "Annotations for Image ID 2:\n",
            "[{'area': 120, 'bbox': [371, 210, 10, 12], 'category_id': 12, 'extra_info': {'human_annotated': 'human', 'occluded': 'no_(fully_visible)'}, 'id': 23, 'image_id': 2, 'iscrowd': False, 'segmentation': [[371, 210, 381, 210, 371, 222, 381, 222]]}, {'area': 216, 'bbox': [185, 218, 27, 8], 'category_id': 12, 'extra_info': {'human_annotated': 'human', 'occluded': '1%_-_70%_occluded_(partially_occluded)'}, 'id': 24, 'image_id': 2, 'iscrowd': False, 'segmentation': [[185, 218, 212, 218, 185, 226, 212, 226]]}, {'area': 1071, 'bbox': [580, 204, 17, 63], 'category_id': 1, 'extra_info': {'human_annotated': 'human', 'occluded': 'no_(fully_visible)', 'specify_if_human_or_not': 'human'}, 'id': 25, 'image_id': 2, 'iscrowd': False, 'segmentation': [[580, 204, 597, 204, 580, 267, 597, 267]]}, {'area': 1612, 'bbox': [474, 241, 52, 31], 'category_id': 2, 'extra_info': {'human_annotated': 'human', 'occluded': '1%_-_70%_occluded_(partially_occluded)'}, 'id': 26, 'image_id': 2, 'iscrowd': False, 'segmentation': [[474, 241, 526, 241, 474, 272, 526, 272]]}, {'area': 2736, 'bbox': [272, 219, 57, 48], 'category_id': 3, 'extra_info': {'human_annotated': 'human', 'occluded': 'no_(fully_visible)'}, 'id': 27, 'image_id': 2, 'iscrowd': False, 'segmentation': [[272, 219, 329, 219, 272, 267, 329, 267]]}, {'area': 7700, 'bbox': [87, 227, 110, 70], 'category_id': 3, 'extra_info': {'human_annotated': 'human', 'occluded': 'no_(fully_visible)'}, 'id': 28, 'image_id': 2, 'iscrowd': False, 'segmentation': [[87, 227, 197, 227, 87, 297, 197, 297]]}, {'area': 425, 'bbox': [239, 233, 25, 17], 'category_id': 3, 'extra_info': {'human_annotated': 'human', 'occluded': 'no_(fully_visible)'}, 'id': 29, 'image_id': 2, 'iscrowd': False, 'segmentation': [[239, 233, 264, 233, 239, 250, 264, 250]]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "gQDTxvHBd0Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install dependencies"
      ],
      "metadata": {
        "id": "-wFqkc29eCgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf "
      ],
      "metadata": {
        "id": "1IHhTxj5eCAk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create model"
      ],
      "metadata": {
        "id": "Up5F3D2KeOpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.shape(train_images[[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zl5IL6Fayk2",
        "outputId": "b5edd25e-8d86-4bf4-ebf0-693e748b1a63"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 512, 640, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "                                     \n",
        "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu, input_shape=(512, 640, 1)),\n",
        "\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "    ])\n",
        "    \n",
        "    return cnn_model\n",
        "  \n",
        "cnn_model = build_cnn_model()\n",
        "# Initialize the model by passing some data through\n",
        "cnn_model.predict(train_images[[0]])\n",
        "# Print the summary of the layers in the model.\n",
        "print(cnn_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k6qaJlpeQu7",
        "outputId": "f12b2be6-a1cd-401b-dc16-c9346bc32991"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_15 (Conv2D)          (None, 510, 638, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPoolin  (None, 255, 319, 32)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 253, 317, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 126, 158, 64)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 1274112)           0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               163086464 \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 163,121,921\n",
            "Trainable params: 163,121,921\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "EjZ3zX0hX-Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aDuXHLoIYIhQ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(train_images, train_labels, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LTNuDdBMX7xc",
        "outputId": "2ac07073-16fa-4aec-b2ff-cc0698e09b03"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f09f84c49bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/sequential_7/conv2d_16/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-31-f09f84c49bd1>\", line 1, in <module>\n      cnn_model.fit(train_images, train_labels, epochs=5)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 531, in minimize\n      loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/sequential_7/conv2d_16/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[32,32,255,319] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/sequential_7/conv2d_16/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9584]"
          ]
        }
      ]
    }
  ]
}