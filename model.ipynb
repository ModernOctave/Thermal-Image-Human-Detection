{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thermal_Image_Human_Detection.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPehCNxKIZwhZ61eTGu6GaJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ModernOctave/Thermal-Image-Human-Detection/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Raw Dataset\n",
        "Download and extract the raw dataset"
      ],
      "metadata": {
        "id": "HG40xyEpbWwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -v https://adas-dataset-v2.flirconservator.com/dataset/full/FLIR_ADAS_v2.zip\n",
        "!unzip -q FLIR_ADAS_v2.zip\n",
        "!rm FLIR_ADAS_v2.zip"
      ],
      "metadata": {
        "id": "fbkXag9e8JGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Dependancies\n"
      ],
      "metadata": {
        "id": "qvHS-zQk8-wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf \n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from pycocotools.coco import COCO\n",
        "import random\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "metadata": {
        "id": "5d-EigR5zlUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create datasets\n",
        "Create custom datasets required by the model"
      ],
      "metadata": {
        "id": "r7x-jwDpzegI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset_path):\n",
        "  # Load the annotations\n",
        "  coco_annotation_file_path = dataset_path+\"coco.json\"\n",
        "  coco_annotation = COCO(annotation_file=coco_annotation_file_path)\n",
        "\n",
        "  # Get all images\n",
        "  img_ids = coco_annotation.getImgIds()[:3000]\n",
        "\n",
        "  # Get category info\n",
        "  cat_ids = coco_annotation.getCatIds()\n",
        "  cat = dict(zip(cat_ids,[cat['name'] for cat in coco_annotation.loadCats(cat_ids)]))\n",
        "\n",
        "  # Segregate images with and without humans\n",
        "  human = []\n",
        "  no_human = []\n",
        "\n",
        "  for i, img_id in enumerate(img_ids):\n",
        "    # Open img\n",
        "    img_info = coco_annotation.loadImgs([img_id])[0]\n",
        "    img_file_name = img_info[\"file_name\"]\n",
        "    im = np.array(Image.open(dataset_path+img_file_name))\n",
        "\n",
        "    # Get all the annotations for the specified image.\n",
        "    ann_ids = coco_annotation.getAnnIds(imgIds=[img_id], iscrowd=None)\n",
        "    anns = coco_annotation.loadAnns(ann_ids)\n",
        "\n",
        "    if 'person' in [cat[ann['category_id']] for ann in anns]:\n",
        "      human.append(im)\n",
        "    else:\n",
        "      no_human.append(im)\n",
        "    \n",
        "    if i%(int(len(img_ids)/10)) == 0:\n",
        "      print(str(int(i/len(img_ids)*100))+\"%\")\n",
        "\n",
        "  half_size = min(len(human),len(no_human))\n",
        "  images = human[:half_size]+no_human[:half_size]\n",
        "  labels = list(np.ones(half_size))+list(np.zeros(half_size))\n",
        "  dataset = list(zip(images, labels))\n",
        "  random.shuffle(dataset)\n",
        "  images, labels = zip(*dataset)\n",
        "  images = (np.expand_dims(images, axis=-1)/255.).astype(np.float32)\n",
        "  labels = np.array(labels).astype(np.int64)\n",
        "  human = None\n",
        "  no_human = None\n",
        "\n",
        "  return images, labels\n",
        "\n",
        "train_images, train_labels = create_dataset('images_thermal_train/')\n",
        "print(\"Training dataset created!\")\n",
        "test_images, test_labels = create_dataset('images_thermal_val/')\n",
        "print(\"Testing dataset created!\")"
      ],
      "metadata": {
        "id": "FxSh-XYT3OeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "gQDTxvHBd0Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the model"
      ],
      "metadata": {
        "id": "uE8cSAGShXvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "                                     \n",
        "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu, input_shape=(512, 640, 1)),\n",
        "\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "\n",
        "        tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "    ])\n",
        "    \n",
        "    return cnn_model\n",
        "  \n",
        "cnn_model = build_cnn_model()\n",
        "\n",
        "# Initialize the model by passing some data through\n",
        "cnn_model.predict(train_images[[0]])\n",
        "\n",
        "# Compile the model\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Print the summary of the layers in the model.\n",
        "print(cnn_model.summary())"
      ],
      "metadata": {
        "id": "_k6qaJlpeQu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "EjZ3zX0hX-Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = tf.keras.models.load_model(\"model.h5\")"
      ],
      "metadata": {
        "id": "RwV0_q9PgyBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.fit(train_images, train_labels, epochs=5)"
      ],
      "metadata": {
        "id": "LTNuDdBMX7xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.save('model.h5')"
      ],
      "metadata": {
        "id": "8O_HfD0CXG-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model\n"
      ],
      "metadata": {
        "id": "NS5yngy6_1dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = cnn_model.evaluate(test_images, test_labels, batch_size=1)"
      ],
      "metadata": {
        "id": "ExSEsv0b_6Nx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}