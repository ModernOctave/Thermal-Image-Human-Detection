{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ModernOctave/Thermal-Image-Human-Detection/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvHS-zQk8-wp"
   },
   "source": [
    "# Install Dependancies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5d-EigR5zlUz"
   },
   "outputs": [],
   "source": [
    "# Import Tensorflow 2.0\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "# assert len(tf.config.list_physical_devices('GPU')) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    human_paths = glob.glob('./dataset/human/*.jpg')\n",
    "    no_human_paths = glob.glob('./dataset/no_human/*.jpg')\n",
    "    if len(human_paths) == 0 or len(no_human_paths) == 0:\n",
    "        raise Exception('Dataset could not be found!')\n",
    "    human_entries = list(zip([cv.imread(path) for path in human_paths], [1 for _ in human_paths]))\n",
    "    no_human_entries = list(zip([cv.imread(path) for path in no_human_paths], [0 for _ in no_human_paths]))\n",
    "    random.shuffle(human_entries)\n",
    "    random.shuffle(no_human_entries)\n",
    "    half_size = min(len(human_entries), len(no_human_entries))\n",
    "    dataset = human_entries[:half_size] + no_human_entries[:half_size]\n",
    "    random.shuffle(dataset)\n",
    "    split_size = int(len(dataset) * 0.8)\n",
    "    train_dataset = dataset[:split_size]\n",
    "    test_dataset = dataset[split_size:]\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "train_dataset, test_dataset = createDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQDTxvHBd0Wg"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE8cSAGShXvZ"
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_k6qaJlpeQu7"
   },
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    cnn_model = tf.keras.Sequential([\n",
    "                                     \n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), activation=tf.nn.relu, input_shape=(24, 32, 1)),\n",
    "\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        tf.keras.layers.Dense(units=64, activation=tf.nn.relu),\n",
    "\n",
    "        tf.keras.layers.Dense(units=1, activation=tf.nn.sigmoid),\n",
    "    ])\n",
    "    \n",
    "    return cnn_model\n",
    "  \n",
    "cnn_model = build_cnn_model()\n",
    "\n",
    "# Initialize the model by passing some data through\n",
    "# cnn_model.predict(train_images[[0]])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the summary of the layers in the model.\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjZ3zX0hX-Q5"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwV0_q9PgyBI"
   },
   "outputs": [],
   "source": [
    "cnn_model = tf.keras.models.load_model(\"yolo_lite.h5\")\n",
    "\n",
    "# Print the summary of the layers in the model.\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LTNuDdBMX7xc"
   },
   "outputs": [],
   "source": [
    "cnn_model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0.01\n",
    "last_accuracy = 0\n",
    "while accuracy > last_accuracy:\n",
    "  cnn_model.fit(train_images, train_labels, epochs=1)\n",
    "  loss, accuracy = cnn_model.evaluate(test_images, test_labels, batch_size=1)\n",
    "print(round(accuracy,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8O_HfD0CXG-w"
   },
   "outputs": [],
   "source": [
    "cnn_model.save('yolov3-tiny.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(cnn_model, \"yolo_lite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NS5yngy6_1dO"
   },
   "source": [
    "## Test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExSEsv0b_6Nx"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = cnn_model.evaluate(test_images, test_labels, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPehCNxKIZwhZ61eTGu6GaJ",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Thermal_Image_Human_Detection.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
